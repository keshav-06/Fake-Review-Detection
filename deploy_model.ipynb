{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43895468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle, nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f67fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('maxent_treebank_pos_tagger')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b19145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89988ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d6d7796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_treebank_pos_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63059460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d826887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Apparel\", \"Automotive\", \"Baby\", \"Beauty\", \"Books\", \"Camera\", \"Electronics\", \"Furniture\", \"Grocery\", \"Health & Personal Care\", \"Home\", \"Home Entertainment\", \"Home Improvement\", \"Jewelry\", \"Kitchen\", \"Lawn and Garden\", \"Luggage\", \"Musical Instruments\", \"Office Products\", \"Outdoors\", \"PC\", \"Pet Products\", \"Shoes\", \"Sports\", \"Tools\", \"Toys\", \"Video DVD\", \"Video Games\", \"Watches\", \"Wireless\"]\n",
    "categories_str = \"Apparel\"\n",
    "for i in range (1, len(categories)) :\n",
    "    categories_str += \", \" + categories[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71674810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "    review = re.sub('[^a-zA-Z]',' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    #print (review)\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69cef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countvectorize(statement):\n",
    "    countvectorizer = pickle.load(open(os.path.join(\"models\", \"countvectorizer.sav\"), 'rb'))\n",
    "    statement = countvectorizer.transform(statement).toarray()\n",
    "    return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c82024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencode(rating, verified_purchase, product_category, X):\n",
    "    labelencoder_1 = pickle.load(open(os.path.join(\"models\", \"labelencoder_1.sav\"), 'rb'))\n",
    "    labelencoder_2 = pickle.load(open(os.path.join(\"models\", \"labelencoder_2.sav\"), 'rb'))\n",
    "    labelencoder_3 = pickle.load(open(os.path.join(\"models\", \"labelencoder_3.sav\"), 'rb'))\n",
    "\n",
    "    ct1 = pickle.load(open(os.path.join(\"models\", \"columntransformer1.sav\"), 'rb'))\n",
    "    ct2 = pickle.load(open(os.path.join(\"models\", \"columntransformer2.sav\"), 'rb'))\n",
    "    ct3 = pickle.load(open(os.path.join(\"models\", \"columntransformer3.sav\"), 'rb'))\n",
    "\n",
    "    w, h = 3, 1;\n",
    "    new_col = [[0 for x in range(w)] for y in range(h)]\n",
    "    num = 0\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        new_col[i][0] = rating\n",
    "        new_col[i][1] = verified_purchase\n",
    "        new_col[i][2] = product_category\n",
    "\n",
    "    new_col = np.array(new_col)\n",
    "\n",
    "    new_col[:, 0] = labelencoder_1.transform(new_col[:, 0])\n",
    "    new_col[:, 1] = labelencoder_2.transform(new_col[:, 1])\n",
    "    new_col[:, 2] = labelencoder_3.transform(new_col[:, 2])\n",
    "\n",
    "    new_col = ct1.transform(new_col)\n",
    "    try:\n",
    "        new_col = new_col.toarray()\n",
    "    except:\n",
    "        #Do Nothing\n",
    "        pass\n",
    "    new_col = new_col.astype(np.float64)\n",
    "\n",
    "    new_col = ct2.transform(new_col)\n",
    "    try:\n",
    "        new_col = new_col.toarray()\n",
    "    except:\n",
    "        #Do Nothing\n",
    "        pass\n",
    "    new_col = new_col.astype(np.float64)\n",
    "\n",
    "    new_col = ct3.transform(new_col)\n",
    "    try:\n",
    "        new_col = new_col.toarray()\n",
    "    except:\n",
    "        #Do Nothing\n",
    "        pass\n",
    "    new_col = new_col.astype(np.float64)\n",
    "\n",
    "    X= np.append(X, new_col, axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09ee8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS_Tagging(sentence):\n",
    "    tagged_list = []\n",
    "    tags = []\n",
    "    count_verbs = 0\n",
    "    count_nouns = 0\n",
    "    text=nltk.word_tokenize(sentence)\n",
    "    tagged_list = (nltk.pos_tag(text))\n",
    "\n",
    "    tags = [x[1] for x in tagged_list]\n",
    "    for each_item in tags:\n",
    "        if each_item in ['VERB','VB','VBN','VBD','VBZ','VBG','VBP']:\n",
    "            count_verbs+=1\n",
    "        elif each_item in ['NOUN','NNP','NN','NUM','NNS','NP','NNPS']:\n",
    "            count_nouns+=1\n",
    "        else:\n",
    "            continue\n",
    "    if count_verbs > count_nouns:\n",
    "        sentence = 'F'\n",
    "    else:\n",
    "        sentence = 'T'\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2add45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag(sentence, X):\n",
    "    w, h = 2, 1;\n",
    "    pos_tag = [[0 for x in range(w)] for y in range(h)]\n",
    "    num = 0\n",
    "\n",
    "    sentence = POS_Tagging(sentence)\n",
    "\n",
    "    if sentence=='T':\n",
    "        pos_tag[0][0] = 1\n",
    "        pos_tag[0][1] = 0\n",
    "    else:\n",
    "        pos_tag[0][0] = 0\n",
    "        pos_tag[0][1] = 1\n",
    "\n",
    "    X = np.append(X, pos_tag, axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "274d9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X):\n",
    "    nb = pickle.load(open(os.path.join(\"models\", \"bernoullinb.sav\"), 'rb'))\n",
    "    svc = pickle.load(open(os.path.join(\"models\", \"SVM.sav\"), 'rb'))\n",
    "    return nb.predict(X)\n",
    "\n",
    "def get_result(statement, rating, verified_purchase, product_category):\n",
    "    X = countvectorize([statement])\n",
    "    X = postag(statement, X)\n",
    "    X = onehotencode(rating, verified_purchase, product_category, X)\n",
    "\n",
    "    X = classify(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4fb64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input(product_rating, verified_purchase, product_category) :\n",
    "    x = True\n",
    "    y = True\n",
    "    z = True\n",
    "\n",
    "    if product_rating != '1' and product_rating != '2' and product_rating != '3' and product_rating != '4' and product_rating != '5' :\n",
    "        print (\"--------------------------------------------------------------------------------------.\")\n",
    "        print (\"\\nError : Product Rating must be Between 1 and 5 (inclusive).\")\n",
    "        print (\"\\nPlease Try Again.\")\n",
    "\n",
    "        x = False\n",
    "\n",
    "    if verified_purchase != 'Y' and verified_purchase != 'N' :\n",
    "        print (\"--------------------------------------------------------------------------------------.\")\n",
    "        print (\"\\nError : Verified Purchase must be either Y (Yes) or N (No).\")\n",
    "        print (\"\\nPlease Try Again.\")\n",
    "\n",
    "        y = False\n",
    "\n",
    "    if product_category not in categories:\n",
    "        print (\"--------------------------------------------------------------------------------------.\")\n",
    "        print (\"\\nError : Product Category must be among these choices : \\n\" + categories_str)\n",
    "        print (\"\\nPlease Try Again.\")\n",
    "\n",
    "        z = False\n",
    "\n",
    "    return [x, y, z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1f81995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your Review : These are a lot bigger than I thought they would be!  I got these as a novelty gift for a friend and they're perfect.  The plastic around the lip isn't sharp either so you can use them to drink out of easily.  They'll hold ten ounces of liquid if you don't fill them to the tippy-top brim.  We hand wash all our glasses so I don't know how machine safe they are, but they seem to be made of a sturdy plastic.  Also the upper cup piece is solid so there's no risk of liquid leaking out the bottom at all.\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Enter your Product Rating (On a scale of 1 to 5) : 5\n",
      "\n",
      "Enter if it's a Verified Purchase (Y or N) : Y\n",
      "\n",
      "Enter your Product Category (Apparel, Automotive, Baby, Beauty, Books, Camera, Electronics, Furniture, Grocery, Health & Personal Care, Home, Home Entertainment, Home Improvement, Jewelry, Kitchen, Lawn and Garden, Luggage, Musical Instruments, Office Products, Outdoors, PC, Pet Products, Shoes, Sports, Tools, Toys, Video DVD, Video Games, Watches, Wireless) : Toys\n",
      "It is a True Review\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    review_text = input(\"\\nEnter your Review : \")\n",
    "\n",
    "    product_rating = \"\"\n",
    "    verified_purchase = \"\"\n",
    "    product_category = \"\"\n",
    "\n",
    "    input_ar = [False, False, False]\n",
    "\n",
    "    while (True) :\n",
    "        print(\"\\n---------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        if not input_ar[0] :\n",
    "            product_rating = input(\"\\nEnter your Product Rating (On a scale of 1 to 5) : \")\n",
    "\n",
    "        if not input_ar[1] :\n",
    "            verified_purchase = input(\"\\nEnter if it's a Verified Purchase (Y or N) : \")\n",
    "\n",
    "        if not input_ar[2] :\n",
    "            product_category = input(\"\\nEnter your Product Category (\" + categories_str + \") : \")\n",
    "\n",
    "        input_ar = test_input(product_rating, verified_purchase, product_category)\n",
    "\n",
    "        if input_ar == [True, True, True] :\n",
    "            break\n",
    "\n",
    "    answer = get_result(review_text, product_rating, verified_purchase, product_category)\n",
    "\n",
    "    if answer == 1:\n",
    "        print (\"It is a True Review\")\n",
    "\n",
    "    else:\n",
    "        print (\"It is a False Review\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc839f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225e50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
